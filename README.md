# Olist Lakehouse

Este projeto constr√≥i um **Lakehouse** para o ecommerce [Olist](https://olist.com/home/), utilizando a [Arquitetura Medallion](https://learn.microsoft.com/en-us/azure/databricks/lakehouse/medallion), que organiza os dados nas camadas **bronze**, **silver** e **gold**.

O objetivo √© demonstrar como estruturar um pipeline de dados moderno, desde a ingest√£o de dados brutos at√© a modelagem dimensional, pronto para an√°lises e BI.

---

## üèóÔ∏è Arquitetura

A arquitetura segue o conceito de **Lakehouse**, que combina as melhores caracter√≠sticas de data lakes e data warehouses.

**Camadas:**
- ü•â **Bronze:** dados brutos, exatamente como foram extra√≠dos do Kaggle.
- ü•à **Silver:** dados limpos, tratados e integrados.
- ü•á **Gold:** modelo dimensional (tabelas `dim_*` e `fct_*`), pronto para consumo anal√≠tico.

![Diagrama do pipeline de dados do Lakehouse](github-assets/olist_architecture_diagram.png)

---

## üîÑ Pipeline de Dados

1. **Ingest√£o:**  
   Airflow (via [Astro](https://www.astronomer.io/product/)) orquestra a extra√ß√£o dos dados do [Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce), armazena no [MinIO](https://min.io/) (Data Lake) e depois carrega no [PostgreSQL](https://www.postgresql.org/) (camada bronze).

2. **Transforma√ß√£o:**  
   O [dbt](https://www.getdbt.com/) aplica as transforma√ß√µes necess√°rias para gerar as camadas **silver** e **gold** dentro do PostgreSQL.

3. **Consumo:**  
   Os dados na camada gold est√£o prontos para an√°lises em ferramentas de BI, notebooks, dashboards, etc.

---
## ‚öôÔ∏è Configura√ß√£o

O projeto foi constru√≠do de que praticamente todas as configura√ß√µes possam ser definidas nos arquivos Docker. 

Entre elas, nota-se principalmente configura√ß√µes de autentica√ß√£o, como username e password.

Uma que merece aten√ß√£o especial √© o **diret√≥rio .dbt**:
- √â necess√°rio alterar, conforme necess√°rio, o caminho do .dbt de acordo com a localiza√ß√£o no seu dispositivo. No `docker-compose.yml`, ele est√° definido como `C:/Users/User/.dbt`, pois era a localiza√ß√£o para o desenvolvedor.  

---

## üöÄ Inicializa√ß√£o

Para adicionar esse reposit√≥rio, execute:
```bash
git clone https://github.com/gabfxv/olist-lakehouse
cd olist-lakehouse
python -m venv .venv
source activate .venv
```

√â necess√°rio o Docker para rodar o projeto.
Caso n√£o o tenha instalado, baixe por [aqui](https://docs.docker.com/engine/).

Para baixar o DBT, √© necess√°rio executar (ou o comando equivalente em Windows):
```bash
pip install -r requirements.txt
mkdir -p ~/.dbt
```

Para subir o PostgreSQL, MinIO e o DBT Docs, execute:
```bash
docker-compose up -d
```

Para iniciar o Astro/Airflow, primeiro instale ele [aqui](https://www.astronomer.io/docs/astro/cli/install-cli/#install-the-astro-cli) e ent√£o, execute:
```bash
cd astro-airflow
astro dev start
```

Para iniciar o OpenMetadata, execute:
```bash
cd openmetadata
docker compose -f docker-compose-postgres.yml up -d
```

Os seguintes servi√ßos est√£o acess√≠veis a partir destas URLs:
- **Astro**: http://localhost:8080
- **Minio**: http://localhost:9001
- **DBT Docs**: http://localhost:8081
- **OpenMetadata**: http://localhost:8585/

## üóÇÔ∏è Modelagem de Dados

A Gold layer segue o seguinte diagrama:

![Diagrama do modelo da gold layer](github-assets/gold_layer_schema.png)

